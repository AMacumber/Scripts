{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & Wrangle\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe\n",
    "df_001 = pd.read_csv(\"Harvey_CorrelationMatrix_v002.csv\", encoding = \"cp1252\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The training set has {0} rows and {1} columns\".format(df_001.shape[0], df_001.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_001.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "### How many features/attributes have missing values? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A total of \", len(df_001.columns[df_001.isnull().any()]), \"features have missing values\")\n",
    "print(\"They are:\", df_001.columns[df_001.isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the percentage of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = df_001.isnull().sum()/len(df_001) #number of missing entries in each feature / number of total entries\n",
    "miss = miss[miss > 0] # keep only those that are greater than \"0 / number of total entries\"\n",
    "miss.sort_values(inplace=True) # sort by percentage ascending\n",
    "miss # display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = miss.to_frame() # convert to a dataframe\n",
    "miss.columns = ['count'] # rename the column as 'count'\n",
    "miss.index.names = ['Name'] # rename index as 'Name'\n",
    "miss['Name'] = miss.index # create a new column of the index\n",
    "\n",
    "#plot the missing value count\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "sns.barplot(x = 'Name', y = 'count', data=miss)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Missing Values (Tutorial_HousingPrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pandas series, with neighborhood as key and grouped values\n",
    "lot_frontage_by_neighborhood = train['LotFrontage'].groupby(train['Neighborhood'])\n",
    "\n",
    "# for key (neighbourhood) and their grouped values in pandas series\n",
    "for key, group in lot_frontage_by_neighborhood:\n",
    "    \n",
    "    # replace any missing values (is.null) with group.median()\n",
    "    idx = (alldata['Neighborhood'] == key) & (alldata['LotFrontage'].isnull())\n",
    "    alldata.loc[idx, 'LotFrontage'] = group.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['SalePrice'])\n",
    "\n",
    "print(\"The skewness of SalePrice is {}\".format(train['SalePrice'].skew()))\n",
    "\n",
    "print(\"The distribution has a right skew. Needs to be normalized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Log Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log(train['SalePrice'])\n",
    "print ('Skewness is', target.skew())\n",
    "sns.distplot(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Numeric and Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = train.select_dtypes(include=[np.number])\n",
    "cat_data = train.select_dtypes(exclude=[np.number])\n",
    "\n",
    "print (\"There are {} numeric and {} categorical columns in train \\\n",
    "data\".format(numeric_data.shape[1],cat_data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = numeric_data.corr()\n",
    "sns.heatmap(corr, cmap=\"PiYG\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (corr['SalePrice'].sort_values(ascending=False)[:15], '\\n') #top 15 values\n",
    "print ('----------------------')\n",
    "print (corr['SalePrice'].sort_values(ascending=False)[-5:]) #last 5 values`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Specific Features\n",
    "\n",
    "Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['OverallQual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check the mean price per quality and plot it.\n",
    "pivot = train.pivot_table(index='GarageCars', values='GarageArea', aggfunc=np.median)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.plot(kind='bar', color='goldenrod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GrLivArea variable\n",
    "sns.jointplot(x=train['GrLivArea'], y=train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pivot = train.pivot_table(index='SaleCondition', values='SalePrice', aggfunc=np.median)\n",
    "sp_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pivot.plot(kind='bar',color='teal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA: Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [f for f in train.columns if train.dtypes[f] == 'object']\n",
    "def anova(frame):\n",
    "    anv = pd.DataFrame()\n",
    "    anv['features'] = cat\n",
    "    pvals = []\n",
    "    for c in cat:\n",
    "           samples = []\n",
    "           for cls in frame[c].unique():\n",
    "                  s = frame[frame[c] == cls]['SalePrice'].values\n",
    "                  samples.append(s)\n",
    "           pval = stats.f_oneway(*samples)[1]\n",
    "           pvals.append(pval)\n",
    "    anv['pval'] = pvals\n",
    "    return anv.sort_values('pval')\n",
    "\n",
    "cat_data['SalePrice'] = train.SalePrice.values\n",
    "k = anova(cat_data) \n",
    "k['disparity'] = np.log(1./k['pval'].values) \n",
    "sns.barplot(data=k, x = 'features', y='disparity') \n",
    "plt.xticks(rotation=90) \n",
    "plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_002 = df_001.dropna(axis=0)\n",
    "\n",
    "print(df_002.shape)\n",
    "print(df_002.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_003 = df_002.drop(['Codes','Lat_dm','Long_dm','Lat_dd','Long_dd','Wind_Speed'], axis = 1)\n",
    "\n",
    "print(df_003.shape)\n",
    "print(df_003.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
